{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37cc29ba",
      "metadata": {
        "id": "37cc29ba"
      },
      "source": [
        "# üìí **JAX Pruebas**\n",
        "\n",
        "En este cuaderno se realizar√°n pruebas pr√°cticas con **JAX**, una librer√≠a desarrollada por Google para computaci√≥n num√©rica y aprendizaje autom√°tico de alto rendimiento. El objetivo es explorar sus principales caracter√≠sticas, como la diferenciaci√≥n autom√°tica, la compilaci√≥n just-in-time (JIT), la vectorizaci√≥n y la ejecuci√≥n acelerada en CPU/GPU/TPU.\n",
        "\n",
        "A lo largo del cuaderno se implementar√°n ejemplos que permitan:\n",
        "\n",
        "* Comprender el funcionamiento b√°sico de JAX.\n",
        "* Comparar su estilo de programaci√≥n con frameworks como TensorFlow y PyTorch.\n",
        "* Evaluar su rendimiento y facilidad de uso en tareas de aprendizaje autom√°tico.\n",
        "\n",
        "<img src=\"https://github.com/Alejandro-BR/jax-research/blob/main/img/jax.png?raw=true\" width=\"150\"/>\n",
        "\n",
        "**Autor: [Alejandro Barrionuevo Rosado](https://github.com/Alejandro-BR)**\n",
        "\n",
        "M√°ster de FP en Inteligencia Artifical y Big Data - CPIFP Alan Turing *texto en cursiva*\n",
        "\n",
        "<img src=\"https://github.com/Alejandro-BR/jax-research/blob/main/img/alan_turing.png?raw=true\" width=\"150\"/>\n",
        "\n",
        "[![Jax Research](https://img.shields.io/badge/jax--research-GitHub-181717?style=flat&logo=github&logoColor=white)](https://github.com/Alejandro-BR/jax-research)\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Alejandro-BR/jax-research/blob/main/notebooks/jax_tests.ipynb)\n",
        "![Python](https://img.shields.io/badge/python-3.12-blue?style=flat&logo=python&logoColor=white)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definici√≥n**\n",
        "\n",
        "JAX es una biblioteca de Python desarrollada por Google para aprendizaje autom√°tico y computaci√≥n num√©rica de alto rendimiento. Su API se basa en **NumPy**, lo que permite trabajar con funciones num√©ricas de manera familiar y sencilla. Gracias a esto, JAX resulta **flexible, f√°cil de aprender y eficiente** para realizar c√°lculos avanzados en CPU, GPU o TPU.\n"
      ],
      "metadata": {
        "id": "nEF9lA9mp4eZ"
      },
      "id": "nEF9lA9mp4eZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Versi√≥n de Python**\n"
      ],
      "metadata": {
        "id": "AyCLtqLMBW_R"
      },
      "id": "AyCLtqLMBW_R"
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJcATS66BPAX",
        "outputId": "e695257e-9f3f-401a-90da-3f1a57ffbef5"
      },
      "id": "QJcATS66BPAX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instalaci√≥n de dependencias**\n",
        "\n",
        "En esta secci√≥n se instalar√°n todas las dependencias que utilizaremos en este cuaderno."
      ],
      "metadata": {
        "id": "mOw28rERuBDB"
      },
      "id": "mOw28rERuBDB"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "p6yxENUuweo9"
      },
      "id": "p6yxENUuweo9",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion de scikit-learn para cargar el conjunto de datos de vino.\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Funcion para dividir los datos en entrenamiento y prueba.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Clase para normalizar los datos (media 0, desviacion estandar 1).\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Funcion para calcular la precision.\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Funcion para la matrix de confusion\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "tzpfUMn0Lb2R"
      },
      "id": "tzpfUMn0Lb2R",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalaci√≥n JAX**\n",
        "\n",
        "<img src=\"https://github.com/Alejandro-BR/jax-research/blob/main/img/jax.png?raw=true\" width=\"150\"/>\n",
        "\n",
        "CPU-only (Linux/macOS/Windows)\n",
        "```python\n",
        "!pip install -U jax\n",
        "```\n",
        "GPU (NVIDIA, CUDA 13)\n",
        "```python\n",
        "!pip install -U \"jax[cuda13]\"\n",
        "```\n",
        "TPU (Google Cloud TPU VM)\n",
        "```python\n",
        "!pip install -U \"jax[tpu]\"\n",
        "```\n",
        "\n",
        "[Instalaci√≥n JAX](https://docs.jax.dev/en/latest/installation.html)"
      ],
      "metadata": {
        "id": "QGIyZ-s2u2Uv"
      },
      "id": "QGIyZ-s2u2Uv"
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU-only (Linux/macOS/Windows)\n",
        "!pip install -U jax\n",
        "# GPU (NVIDIA, CUDA 13)\n",
        "# !pip install -U \"jax[cuda13]\"\n",
        "# TPU (Google Cloud TPU VM)\n",
        "# !pip install -U \"jax[tpu]\"\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Backend (CPU/GPU/TPU):\", jax.devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-3_U3m1teqp",
        "outputId": "8be61ff2-28cd-4e02-f95d-a62a4e59782a"
      },
      "id": "L-3_U3m1teqp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (0.7.2)\n",
            "Collecting jax\n",
            "  Downloading jax-0.9.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.9.0.1,>=0.9.0.1 (from jax)\n",
            "  Downloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax) (1.16.3)\n",
            "Downloading jax-0.9.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "Successfully installed jax-0.9.0.1 jaxlib-0.9.0.1\n",
            "JAX version: 0.9.0.1\n",
            "Backend (CPU/GPU/TPU): [CpuDevice(id=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalaci√≥n de TensorFlow**\n",
        "\n",
        "<img src=\"https://github.com/Alejandro-BR/jax-research/blob/main/img/tensorflow_logo.svg.png?raw=true\" width=\"150\"/>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mLZf9IvnwAwR"
      },
      "id": "mLZf9IvnwAwR"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"Versi√≥n de TensorFlow:\", tf.__version__)\n",
        "print(\"GPU disponible:\", \"S√≠\" if tf.config.list_physical_devices('GPU') else \"No\")\n",
        "print(\"Versi√≥n de Keras:\", keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHOmDplov-fD",
        "outputId": "67f5ed57-0dfa-4534-f2a2-74b147b11627"
      },
      "id": "mHOmDplov-fD",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versi√≥n de TensorFlow: 2.19.0\n",
            "GPU disponible: No\n",
            "Versi√≥n de Keras: 3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalaci√≥n de PyTorch**\n",
        "\n",
        "<img src=\"https://github.com/Alejandro-BR/jax-research/blob/main/img/pytorch.webp?raw=true\" width=\"150\"/>\n"
      ],
      "metadata": {
        "id": "yXTd37q4wQ8d"
      },
      "id": "yXTd37q4wQ8d"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"Versi√≥n de PyTorch:\", torch.__version__)\n",
        "print(\"GPU disponible:\", \"S√≠\" if torch.cuda.is_available() else \"No\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dU8ocCwQZW",
        "outputId": "9871e9ad-a97b-4ee5-bb85-f5773fd43650"
      },
      "id": "F_dU8ocCwQZW",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versi√≥n de PyTorch: 2.9.0+cpu\n",
            "GPU disponible: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ecosistema**\n",
        "\n",
        "Librer√≠as implementadas sobre JAX y otras herramientas que se integran bien con esta tecnolog√≠a.\n",
        "\n",
        "### Ejemplos de librer√≠as que usan JAX\n",
        "\n",
        "1. **Flax** ‚Äì Librer√≠a para construir redes neuronales de manera modular y flexible.\n",
        "2. **Haiku** ‚Äì Otra librer√≠a de alto nivel para redes neuronales en JAX.\n",
        "3. **Optax** ‚Äì Optimizadores y funciones de actualizaci√≥n para entrenamiento de modelos.\n",
        "4. **Chex** ‚Äì Utilidades para pruebas, depuraci√≥n y validaci√≥n de modelos.\n",
        "5. **Distrax** ‚Äì Distribuciones de probabilidad y herramientas para modelado probabil√≠stico.\n",
        "6. **JAX MD** ‚Äì Din√°mica molecular y simulaciones f√≠sicas.\n",
        "7. **Objax** ‚Äì Framework ligero para deep learning en JAX.\n",
        "8. **Evox** ‚Äì Evoluci√≥n y algoritmos gen√©ticos con JAX.\n",
        "9. **BraX** ‚Äì Simulaciones f√≠sicas aceleradas por hardware, integraci√≥n con JAX.\n",
        "10. **Jraph** ‚Äì Librer√≠a para grafos y redes neuronales sobre grafos (GNNs) con JAX.\n"
      ],
      "metadata": {
        "id": "9DM9QGtCCvpf"
      },
      "id": "9DM9QGtCCvpf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **jax.numpy**\n",
        "\n",
        "![jnp](https://github.com/Alejandro-BR/jax-research/blob/main/img/np_vs_jnp.webp?raw=true)\n",
        "\n",
        "[jax.numpy](https://docs.jax.dev/en/latest/jax.numpy.html) es como NumPy, pero acelerado y diferenciable, y jnp es solo el nombre corto que usamos para llamar a esas funciones.\n",
        "\n",
        "A diferencia de Numpy, que solo se ejecuta en CPU, JAX admite operaciones de matriz en m√∫ltiples aceleradores, incluyendo CPU, GPU y TPU. Esta capacidad permite a JAX gestionar eficientemente c√°lculos a gran escala y tareas de aprendizaje profundo, aprovechando el procesamiento paralelo para aumentar significativamente el rendimiento.\n",
        "\n",
        "> Esta secci√≥n est√° basada en: [jax-vs-numpy-key-differences-and-benefits](https://medium.com/@harshavardhangv/jax-vs-numpy-key-differences-and-benefits-72e442bbf67f)\n",
        "\n",
        "\n",
        "```python\n",
        "import jax.numpy as jnp\n",
        "```"
      ],
      "metadata": {
        "id": "9c0iaenE25oq"
      },
      "id": "9c0iaenE25oq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Consideraciones importantes al usar JAX**"
      ],
      "metadata": {
        "id": "eS7fpaDo76cC"
      },
      "id": "eS7fpaDo76cC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Inmutabilidad\n",
        "   - Los arrays de JAX son **inmutables**. No se pueden modificar directamente como en NumPy.\n",
        "   - Para actualizar valores espec√≠ficos se usan `.at[index].set(valor)`:"
      ],
      "metadata": {
        "id": "y0Kx5vus8Bvb"
      },
      "id": "y0Kx5vus8Bvb"
    },
    {
      "cell_type": "code",
      "source": [
        "array = jnp.array([ 1 , 2 , 3 , 4 ])\n",
        "\n",
        "# La asignaci√≥n directa como en NumPy generar√° un error\n",
        "# array[1] = 3 # Descomentar esta l√≠nea generar√° un error\n",
        "\n",
        "# Usa .at para especificar el √≠ndice y .set para actualizar el valor\n",
        "array = array.at[ 1 ]. set ( 3 )\n",
        "\n",
        "# Imprime la matriz actualizada\n",
        "print(array)   # Salida: [1, 3, 3, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTU4lLcH8Eca",
        "outputId": "271bcbd9-e5a4-444e-bc65-515052472892"
      },
      "id": "JTU4lLcH8Eca",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 3 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Funciones puras\n",
        "\n",
        "   * JAX requiere que las funciones sean **puras**: siempre devuelven la misma salida para la misma entrada y no modifican estados externos.\n",
        "   * JAX no puede compilar funciones que alteren variables globales\n",
        "  "
      ],
      "metadata": {
        "id": "iyv9_Ys29Jj7"
      },
      "id": "iyv9_Ys29Jj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una variable global\n",
        "global_var = 0\n",
        "\n",
        "# Define una funci√≥n no pura que modifica la variable global\n",
        "def  impure_function ( x ):\n",
        "    global global_var\n",
        "    global_var = x\n",
        "    return x\n",
        "\n",
        "# Compilaci√≥n JIT de JAX\n",
        "jitted_function = jax.jit(impure_function)\n",
        "print (jitted_function( 5.0 ))\n",
        "\n",
        "# Imprime la variable global\n",
        "print ( \"Variable global:\" , global_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr-y9s5M9O0c",
        "outputId": "1888bced-cca7-480f-bd89-7446b263b4de"
      },
      "id": "Hr-y9s5M9O0c",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n",
            "Variable global: JitTracer(~float32[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado anterior se debe a que jax.jitla compilaci√≥n espera una funci√≥n pura pero encontr√≥ una funci√≥n no pura y esto arroj√≥ un resultado inesperado."
      ],
      "metadata": {
        "id": "lockupvB-bhB"
      },
      "id": "lockupvB-bhB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Indexaci√≥n fuera de l√≠mites\n",
        "\n",
        "   * NumPy lanza `IndexError` si un √≠ndice est√° fuera de rango. JAX ajusta el √≠ndice al l√≠mite v√°lido:"
      ],
      "metadata": {
        "id": "qnRls9Fz-HJd"
      },
      "id": "qnRls9Fz-HJd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy\n",
        "# Inicializar la matriz\n",
        "array = np.array([ 1 , 2 , 3 , 4 ])\n",
        "\n",
        "# imprimir el √≠ndice fuera de los l√≠mites\n",
        "# print(array[ 6 ]) # genera un IndexError\n",
        "\n",
        "# JAX\n",
        "# Inicializar la matriz\n",
        "array = jnp.array([ 1 , 2 , 3 , 4 ])\n",
        "\n",
        "# imprimir el √≠ndice fuera de los l√≠mites\n",
        "print(array[ 6 ], array[- 3 ]) # imprime (4, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW8oYt767u9q",
        "outputId": "3fb6ff44-bf38-4cc1-bfd1-c68026b02f8e"
      },
      "id": "dW8oYt767u9q",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Entradas deben ser arrays\n",
        "\n",
        "* JAX no acepta directamente listas o tuplas en operaciones num√©ricas.\n",
        "* Hay que **transformarlas a un array de JAX (`jnp.array`)** antes de usarlas.\n"
      ],
      "metadata": {
        "id": "WDJPTkVw-T9T"
      },
      "id": "WDJPTkVw-T9T"
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [1, 2, 3]\n",
        "array = jnp.array(lista)\n",
        "print(jnp.sum(array))  # 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRTDivDb-Use",
        "outputId": "be863e9e-a8ef-422d-8d7f-61ac1a780025"
      },
      "id": "zRTDivDb-Use",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Tipos de datos\n",
        "\n",
        "Los tipos de datos son pr√°cticamente iguales a NumPy."
      ],
      "metadata": {
        "id": "7g7ugsu3B7rl"
      },
      "id": "7g7ugsu3B7rl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejemplo pr√°ctico**\n",
        "\n",
        "En este bloque realizaremos **pruebas pr√°cticas con `jax.numpy`**, la implementaci√≥n de NumPy dentro de JAX.\n",
        "\n"
      ],
      "metadata": {
        "id": "3qbnjbJc_hjM"
      },
      "id": "3qbnjbJc_hjM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crear arrays"
      ],
      "metadata": {
        "id": "zu3UHY5y_oBv"
      },
      "id": "zu3UHY5y_oBv"
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = jnp.array([1, 2, 3, 4])\n",
        "array2 = jnp.array([[1, 2], [3, 4]])\n",
        "\n",
        "print(\"Array 1:\", array1)\n",
        "print(\"Array 2:\\n\", array2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cst7m876_uTr",
        "outputId": "3b244602-cada-4282-d0af-5588643ee00e"
      },
      "id": "cst7m876_uTr",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array 1: [1 2 3 4]\n",
            "Array 2:\n",
            " [[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operaciones"
      ],
      "metadata": {
        "id": "6mLTU_Fx_9NQ"
      },
      "id": "6mLTU_Fx_9NQ"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Array:\", array1)\n",
        "print(\"Suma de array1:\", jnp.sum(array1))\n",
        "print(\"Media de array1:\", jnp.mean(array1))\n",
        "print(\"Mediana de array1:\", jnp.median(array1))\n",
        "\n",
        "# Moda (no existe directa, se calcula as√≠)\n",
        "values, counts = jnp.unique(array1, return_counts=True)\n",
        "mode = values[jnp.argmax(counts)]\n",
        "print(\"Moda de array1:\", mode)\n",
        "\n",
        "print(\"Producto de array1:\", jnp.prod(array1))\n",
        "print(\"M√°ximo de array1:\", jnp.max(array1))\n",
        "print(\"M√≠nimo de array1:\", jnp.min(array1))\n",
        "print(\"Desviaci√≥n est√°ndar de array1:\", jnp.std(array1))\n",
        "print(\"Varianza de array1:\", jnp.var(array1))\n",
        "print(\"Suma acumulada de array1:\", jnp.cumsum(array1))\n",
        "print(\"Producto acumulado de array1:\", jnp.cumprod(array1))\n",
        "print(\"Producto punto de array1 consigo mismo:\", jnp.dot(array1, array1))\n",
        "print(\"Array ordenado:\", jnp.sort(array1))\n",
        "print(\"Ra√≠z cuadrada de array1:\", jnp.sqrt(array1))\n",
        "print(\"Array al cuadrado:\", jnp.power(array1, 2))\n",
        "print(\"Valor absoluto de array1:\", jnp.abs(array1))\n",
        "print(\"Array redondeado:\", jnp.round(array1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF6xkXX0__yp",
        "outputId": "1d710baf-1687-4625-a4fc-160e45dbcce1"
      },
      "id": "wF6xkXX0__yp",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array: [1 2 3 4]\n",
            "Suma de array1: 10\n",
            "Media de array1: 2.5\n",
            "Mediana de array1: 2.5\n",
            "Moda de array1: 1\n",
            "Producto de array1: 24\n",
            "M√°ximo de array1: 4\n",
            "M√≠nimo de array1: 1\n",
            "Desviaci√≥n est√°ndar de array1: 1.118034\n",
            "Varianza de array1: 1.25\n",
            "Suma acumulada de array1: [ 1  3  6 10]\n",
            "Producto acumulado de array1: [ 1  2  6 24]\n",
            "Producto punto de array1 consigo mismo: 30\n",
            "Array ordenado: [1 2 3 4]\n",
            "Ra√≠z cuadrada de array1: [1.        1.4142135 1.7320508 2.       ]\n",
            "Array al cuadrado: [ 1  4  9 16]\n",
            "Valor absoluto de array1: [1 2 3 4]\n",
            "Array redondeado: [1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indexaci√≥n y slicing"
      ],
      "metadata": {
        "id": "5grxZ1AjAqxK"
      },
      "id": "5grxZ1AjAqxK"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Primer elemento de array1:\", array1[0])\n",
        "print(\"√öltimos dos elementos de array1:\", array1[-2:])\n",
        "print(\"Fila 0 de array2:\", array2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ui71-sAsw3",
        "outputId": "d82d82e9-065a-4898-8f5a-7000c0332b20"
      },
      "id": "i0ui71-sAsw3",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primer elemento de array1: 1\n",
            "√öltimos dos elementos de array1: [3 4]\n",
            "Fila 0 de array2: [1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inmutabilidad - Actualizar valores usando `.at[].set()`"
      ],
      "metadata": {
        "id": "tyy9BXXcAysS"
      },
      "id": "tyy9BXXcAysS"
    },
    {
      "cell_type": "code",
      "source": [
        "# array1[1] = 10  # Esto dar√≠a error"
      ],
      "metadata": {
        "id": "9rzgTVUcA2Pb"
      },
      "id": "9rzgTVUcA2Pb",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1_updated = array1.at[1].set(10)\n",
        "print(\"\\nArray1 actualizado:\", array1_updated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN1QNI8sA5Ab",
        "outputId": "3a11e31c-1d8e-454e-c182-0ad0c3463c5b"
      },
      "id": "UN1QNI8sA5Ab",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Array1 actualizado: [ 1 10  3  4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clasificaci√≥n de vinos en tres frameworks**\n",
        "\n",
        "El **dataset [`wine`](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset)** es un conjunto de datos cl√°sico en machine learning que contiene informaci√≥n sobre las **caracter√≠sticas qu√≠micas de distintos vinos** cultivados en Italia. Cada muestra incluye 13 atributos num√©ricos, como contenido de alcohol, √°cido m√°lico, flavonoides y otras propiedades qu√≠micas, que permiten distinguir entre **tres tipos de cultivares**.\n",
        "\n",
        "El objetivo de este ejercicio es **comparar la implementaci√≥n de una red neuronal para clasificaci√≥n multiclase** utilizando tres frameworks de deep learning:\n",
        "\n",
        "1. **PyTorch**\n",
        "2. **JAX / Flax**\n",
        "3. **Keras / TensorFlow**\n",
        "\n",
        "En este ejercicio se abordar√°n los siguientes puntos:\n",
        "\n",
        "* Preparaci√≥n y normalizaci√≥n de los datos para entrenamiento.\n",
        "* Definici√≥n de la misma **arquitectura de red neuronal** en los tres frameworks.\n",
        "* Entrenamiento y evaluaci√≥n del modelo en cada framework.\n",
        "* Comparaci√≥n de sintaxis, facilidad de uso, rendimiento y flexibilidad de cada herramienta.\n",
        "\n",
        "De esta manera, se podr√° observar c√≥mo **la misma tarea de clasificaci√≥n** puede implementarse de forma similar en distintos ecosistemas de deep learning, resaltando las ventajas y caracter√≠sticas de cada uno.\n",
        "\n"
      ],
      "metadata": {
        "id": "AdM99b6YHnZh"
      },
      "id": "AdM99b6YHnZh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bibliografia**\n",
        "\n",
        "- [jax](https://docs.jax.dev/en/latest/)\n",
        "- [chatgpt](https://chatgpt.com/)\n",
        "- [eiposgrados](https://eiposgrados.com/blog-python/jax-machine-learning/#:~:text=JAX%20es%20una%20nueva%20biblioteca,flexible%20y%20f%C3%A1cil%20de%20aprender.)\n",
        "- [medium](https://medium.com/@harshavardhangv/jax-vs-numpy-key-differences-and-benefits-72e442bbf67f)"
      ],
      "metadata": {
        "id": "NV-cjRaQqjza"
      },
      "id": "NV-cjRaQqjza"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}